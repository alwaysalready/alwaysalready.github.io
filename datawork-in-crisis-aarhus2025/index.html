<!doctype html>
<html>

<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link href="https://unpkg.com/tailwindcss@^2/dist/tailwind.min.css" rel="stylesheet">
    <link href="./css/styles.css" rel="stylesheet">
    <!-- ... -->
    <title>
        Data/Work in Crisis
    </title>
    <link rel="shortcut icon" href="media/1628499483.ico" type="image/x-icon">
</head>

<body>
    <header>
        <div class="container lg:h-screen xl:h-auto mx-auto pt-20 px-4">
            <div class="grid grid-cols-1 space-y-6">
                <div class="z-40">
                    <h1 class="font-black text-6xl">Data/Work in Crisis</h1>
                </div>
                <div>
                    <h2 class="font-bold text-5xl">An <a href="https://cscw.acm.org/2021/" target="_new">Aarhus 2025</a> workshop</h2>
                    <div class="mt-3">Monday or Tuesday, August 18/19, 2025</div>
                    <div>Aarhus, Denmark</div>
                    <svg class="float-right overflow-visible" xmlns="http://www.w3.org/2000/svg">
                        <circle cx="20" cy="0" r="500" fill="red" />
                    </svg>
                </div>
            </div>
        </div>
    </header>
    <div class="container mx-auto px-4">
        <div class="grid grid-cols-12 space-y-6 sm:w-9/12">
            <div class="md:col-span-10 col-span-12">
                <div>
                    <p class="text-2xl">This one-day workshop aims to map data and its inherent connections to work (of all kinds) across a landscape of ongoing crises. The workshop brings together researchers and practitioners with an interest in data work that underpins automation, algorithmic systems and organizational and societal strives toward datafication. The workshop provides a forum for interdisciplinary discussions around controversies related to data and work – and data work in particular – with the aim to expand the toolbox for working with data by proposing and developing critical approaches, drawing on the rich contributions of the growing body of literature on data work and datafication. Through spatial and temporal mapping exercises, the workshop intends to both trace paths through past crises into a contemporary moment, and towards more hopeful futures. (Read illustrative controversies.)</p>
                </div>
                <!-- <div>
                    <svg class="float-left overflow-visible">
                        <line x1="-100" y1="-400" x2="700" y2="400" stroke="black" />
                    </svg>
                </div> -->
            </div>

            <div class="lg:col-span-8 md:col-span-8 col-span-12 space-y-5 lg:pt-80">
                <h2 class="font-bold text-5xl mt-16">Illustrative controversies</h2>
                <p>Rather than defining specific conference themes, we offer here some illustrative controversies for opening up the conversation. The work of the workshop will be to expand and deepen this list and produce a generative mapping, along with thinking through what we can take from the past decade of scholarship and build upon.</p>
                
                <h3 class="font-bold text-4xl mt-12">Erosion of skill and the meaning of work</h3>
                <p>Working with an expansive definition of data work as “any human activity related to creating, collecting, managing, curating, analyzing, interpreting, and communicating data” [6], we are all becoming data workers. Data-driven moves to outsource and automate work commonly lead to the transformation of work rather than machines replacing human effort [19, 26]. This raises controversy over how we might (or fail to) protect values of skill, care, and experienced meaning in work. Within the HCI/CSCW literature, there are at least four meanings of data work that are of interest for this workshop: (1) data work in pre-existing work practice that is getting datafied (e.g. [14, 19]), (2) the data work that data scientists do (and would like to avoid doing) to clean and prepare data sets (e.g. [1, 4, 20, 21]), (3) data work that is outsourced to click workers (e.g. [9, 28], and (4) data work that is delegated to algorithms (e.g. [13]).</p>
                
                <h3 class="font-bold text-4xl mt-12">Invisibility of data/work and its emotional burdens</h3>
                <p>As a related controversy, narratives of automation and datafication risk losing sight of work practice and the emotional burdens it may involve, especially when it comes to data practices like content moderation or red-teaming. Data work is often invisible, uncompensated work that disproportionately burdens those low in organizational hierarchies [3, 19]. Data work tasks are assigned to workers at all levels without attention to the labor data work requires. In the wake of Big Data and AI, research on data work has paid disproportionate attention to the practices of data scientists and data analytics [24]. However, data work entails multiple forms of labor carried out by professionals and laypeople who do data work adjacent to their core work tasks and data work professionals alike [5].</p>
                
                <h3 class="font-bold text-4xl mt-12">Inequalities around data/work</h3>
                <p>There is a need to understand how power relations surrounding data work operate at both micro as well at macro levels of scale. Research shows there are differences in global experiences of data work [12, 18, 25, 27], with data work in the global south often following the historical fault lines of colonialism [23]. Thus, there is a pressing need for interdisciplinary scholarly attention to data work that attends to power at multiple levels of analysis, from the micro (individual, organizational) to the macro (global). Moreover, these inequalities are echoed in data and their production.Data often reflect social inequalities along historical, geographical and socio-economic lines. For instance, geographies of previously colonised lands may be valued less for their use than they are valued as sites for extraction [10], with datafication reflecting economic rather than social needs. The systems and logics of datafication are imposed even in humanitarian contexts [15] and at local levels, marginalised communities may have and be given less access to data and derive less value from its political power [11].</p>
            </div>
            
            
            
            <div class="lg:col-span-5 md:col-span-8 col-span-12">
                <h2 class="font-bold text-5xl mt-16">Submitting</h2>
                <p>The submission deadline is TBC.</p>

                <div class="my-10">
                    <div class="pr-40"> 
                        <a href="https://airtable.com/appYs6EJFz28rDpQr/pagd5h2vVvEBAMohG/form" target="_new">
                            <button class="ring-4 h-full w-full p-4 ring-red-500 bg-red-400 hover:bg-red-700 hover:text-white">
                                <span class="font-bold text-white text-center hover:bg-red-700 ">Submit</span>
                            </button>
                        </a>
                    </div>
                    <div class="py-auto">
                        <p class="text-sm py-3">Use this button to submit to the workshop.</p>
                    </div>
                </div>

                <div class="md:col-span-10 col-span-12 space-y-3">
                    <p>Those interested in the workshop are invited to fill in the submission form, including a 250-300 word provocation on the state of crisis within data/work, participant's name, email address, affiliation and title, 50-100-word bio, and a list of three favourite books/papers/websites related to data/work. Submissions will be reviewed by the organisers and accepted based on the relevance and development of their chosen topic, as well as participants’ potential to contribute to the workshop.</p>
                    <p>Selection will rely on an inclusive model, where we will as organisers especially welcome work that represents a diverse community of scholarship and practice.</p>
                    <p>Notifications of acceptance will be sent by TBC.</p>
                </div>
            </div>
        </div>

        <div class="grid grid-cols-4 grid-rows-9 gap-4 mb-10">

            <div class="md:col-start-3 md:col-span-3 col-span-4">
                <h2 class="font-bold text-5xl mt-16">Organisers</h2>
            </div>

            <div class="md:col-start-2 p-1">
                <a href="https://researchprofiles.ku.dk/en/persons/naja-holten-m%C3%B8ller" target="_new"><img class="object-contain w-full rounded-lg" src="https://researchprofiles.ku.dk/files-asset/165281782/AAEAAQAAAAAAAAdpAAAAJGJiYjgyMjdlLTEwOTItNDg5Yi1iZTQzLTg1MGVhNGExNWM4Zg.jpg" alt="Benedetta Catanzariti"></a>
            </div>
            <div class="md:col-span-2 col-span-3">
                <span class="font-bold"><a href="https://researchprofiles.ku.dk/en/persons/naja-holten-m%C3%B8ller" target="_new">Naja Holten Møller</a></span> explores how adaptive data-driven technologies introduce continual forms bureaucracies and public decision-, but also for citizens and others who engage with these work processes. In this context, her work raises questions about the role of professional discretion as automation is introduced to decision-making. She is an Associate Professor in Computer-Supported Cooperative Work at the University of Copenhagen.
            </div>

            <div class="md:col-start-2 p-1">
                <a href="http://airilampinen.fi/" target="_new"><img class="object-contain w-full rounded-lg" src="/media/airi_lampinen.jpg" alt="airi lampinen"></a>
            </div>
            <div class="md:col-span-2 col-span-3">
                <span class="font-bold"><a href="http://airilampinen.fi/" target="_new">Airi Lampinen</a></span> studies algorithmic systems, with a particular focus on interpersonal and economic encounters. Her current research focuses on shared uses of intimate technology and the layered trust relationships prevalent in engagement with intimate digital health technologies. Lampinen is an Associate Professor in Human–Computer Interaction at Stockholm University, Sweden, and a Docent in Social Psychology at the University of Helsinki, Finland.
            </div>
            
            <div class="md:col-start-2 p-1">
                <a href="https://www.kth.se/profile/rcomber" target="_new"><img class="object-contain w-full rounded-lg" src="https://www.kth.se/files/avatar/rcomber" alt="Rob Comber"></a>
            </div>
            <div class="md:col-span-2 col-span-3">
                <span class="font-bold"><a href="https://www.kth.se/profile/rcomber" target="_new">Rob Comber</a></span> studies the social and environmental sustainability of civic technologies with local, national, and international civic organisations. Taking a critical perspective on what is asked of people in the work to make civic systems work, he has investigated questions on the political, emotional, legal, and recently (de)colonial dimensions of design. He is an Associate Professor in Communication at KTH Royal Institute of Technology, in Stockholm, Sweden.
            </div>
            
            <div class="md:col-start-2 p-1">
                <a href="https://srravya.github.io/" target="_new"><img class="object-contain w-full rounded-lg" src="media/Srrayva+Chandhiramowuli.jpg" alt="Srrayva Chandhiramowuli"></a>
            </div>
            <div class="md:col-span-2 col-span-3">
                <span class="font-bold"><a href="https://srravya.github.io/" target="_new">Srrayva Chandhiramowuli</a></span> examines the role of human values in data annotation and AI development. Her current research examines the work of data annotation for AI, paying particular attention to systemic challenges and frictions, to envision and inform just, equitable futures of AI. She is a PhD candidate in the Institute for Design Informatics at the University of Edinburgh.
            </div>
            <div class="md:col-start-2 p-1">
                <a href="https://ast.io" target="_new"><img class="object-contain w-full rounded-lg" src="media/Alex+Taylor.jpg" alt="Alex Taylor"></a>
            </div>
            <div class="md:col-span-2 col-span-3">
                <span class="font-bold"><a href="https://ast.io" target="_new">Alex Taylor</a></span> has been contributing to Science & Technology Studies and Human-Computer Interaction (HCI) for over twenty years. His interests are in how digital technologies are co-constitutive of forms of knowing and doing, and, as a consequence, provide a basis for fundamental transformations in society. He is a Reader at Design Informatics, University of Edinburgh.
            </div>
            
            <div class="md:col-start-2 p-1">
                <a href=https://pure.au.dk/portal/en/persons/clausbossen@cc.au.dk" target="_new"><img class="object-contain w-full rounded-lg" src="/media/claus_bossen.jpg" alt="Clauss Bossen"></a>
            </div>
            <div class="md:col-span-2 col-span-3">
           <span class="font-bold"><a href="https://pure.au.dk/portal/en/persons/clausbossen@cc.au.dk" target="_new">Claus Bossen</a></span> investigates the development and accommodation of IT in healthcare. Currently, he focuses on the different kinds of data work that emerges in connection with datafication of healthcare and efforts to become data-informed or -driven. This includes new data work tasks for healthcare professionals as well as new occupations such as clinical documentation integrity specialists. He is professor at Information Studies, Aarhus University.
            </div>
            
            <div class="md:col-start-2 p-1">
                <a href="https://search.asu.edu/profile/696899" target="_new"><img class="object-contain w-full rounded-lg" src="/media/k_pine.png" alt="Katie Pine"></a>
            </div>
            <div class="md:col-span-2 col-span-3">
            <span class="font-bold"><a href="https://search.asu.edu/profile/696899" target="_new">Kathleen Pine</a></span> studies data practices: the situated social, technical, and organizational practices through which data are created, managed, and deployed, as well as the social and organizational implications of digital information technologies in the realms of healthcare and community health. She is an Associate Professor in the College of Health Solutions at Arizona State University
            </div>

        </div>

        <div class="grid grid-cols-1 md:grid-cols-6 md:gap-3 space-y-4 mb-10">
            <div class="md:col-span-6">
                <h2 class="font-bold text-5xl mt-16">Planning</h2>
            </div>

            <div class="md:col-span-1">
                <h3 class="font-semibold text-lg">Duration:</h3>
                <p class="text-sm">The workshop will be hosted in-person in Aarhus Denmark, on either August 18 or 19.</p>
            </div>

            <div class="md:col-span-3">
                <h3 class="font-semibold text-lg">Activities:</h3>
                <div class="text-sm space-y-3">
                    <p>The workshop is structured as a full-day, in-person event, centring on mapping the crises surrounding data/work using materials participants bring and present as a starting point. We will employ controversy mapping [16], a form of analysis that has been developed in the social sciences and has an established methodology for working on sociotechnical controversies in diverse groups and with creative resources [17]. A series of controversy mapping exercises will be geared towards community building and expanding the space in which to work critically on/with data, data work, and datafication.</p>
                </div>
            </div>

            <div class="md:col-span-2">
                <h3 class="font-semibold text-lg">Goals:</h3>
                <div class="text-sm space-y-3">
                    <p>The key objective of this workshop is to bring together researchers within (and where possible beyond) the HCI/CSCW 160 community with an interest in data/work, with the aims of sharing ongoing research, facilitating relationships around shared research interests, and collectively reflecting on the roles and contributions of scholars have made over the past decade and can hope to make in the decade to come. More concretely, we intend this workshop to deliver a set of literature recommendations on data/crisis and an articulation of grand challenges to pursue in the coming decade.</p>
                </div>

            </div>
        </div>

        <div class="grid grid-cols-1 md:grid-cols-2 md:gap-3 mb-10" id="long-text">
            <div class="md:col-span-2">


            </div>

            <div class="grid grid-cols-1 mb-10">
                <div class="md:col-span-2">
                    <h2 class="font-bold text-2xl mt-12 mb-5">References</h2>
                </div>

                <div class="text-xs space-y-3">
                    <p>[1] Angel Au-Yeung. 2021. At Risk Of Losing Their Jobs, Facebook Content Moderators In Ireland Speak Out Against Working Conditions. Retrieved June 11, 2021 from <a href="https://www.forbes.com/sites/angelauyeung/2021/01/29/facebook-content-moderators-in-ireland-meet-deputy-prime-ministerspeak-out-against-working-conditions/?sh=2bcc1650321d"
                            targer="_new">URL</a>.</p>

                    <p>[2] Paško Bilić. 2016. Search algorithms, hidden labour and information control. Big Data & Society 3, 1 (2016), 2053951716652159.</p>

                    <p>[3] Kate Crawford. 2021. The Atlas of AI. Yale University Press.</p>

                    <p>[4] Tarleton Gillespie. 2020. Content moderation, AI, and the question of scale. Big Data & Society 7, 2 (2020).</p>

                    <p>[5] Mary L Gray and Siddharth Suri. 2019. Ghost work: How to stop Silicon Valley from building a new global underclass. Eamon Dolan Books.</p>

                    <p>[6] Ben Hutchinson, Andrew Smart, Alex Hanna, Emily Denton, Christina Greer, Oddur Kjartansson, Parker Barnes, and Margaret Mitchell. 2021. Towards Accountability for Machine Learning Datasets: Practices from Software Engineering and
                        Infrastructure. In Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency (Virtual Event, Canada) (FAccT ’21). Association for Computing Machinery, New York, NY, USA, 560–575. <a href="https://doi.org/10.1145/3442188.3445918"
                            targer="_new">URL</a>.</p>

                    <p>[7] Lilly C. Irani and M. Six Silberman. 2013. Turkopticon: Interrupting Worker Invisibility in Amazon Mechanical Turk. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Paris, France) (CHI ’13). Association
                        for Computing Machinery, New York, NY, USA, 611–620. <a href="https://doi.org/10.1145/2470654.2470742" targer="_new">URL</a>.</p>

                    <p>[8] Milagros Miceli, Tianling Yang, Laurens Naudts, Martin Schuessler, Diana Serbanescu, and Alex Hanna. 2021. Documenting Computer Vision Datasets: An Invitation to Reflexive Data Practices. In Proceedings of the 2021 ACM Conference
                        on Fairness, Accountability, and Transparency (Virtual Event, Canada) (FAccT ’21). Association for Computing Machinery, New York, NY, USA, 161–172. <a href="https://doi.org/10.1145/3442188.3445880" targer="_new">URL</a>.</p>

                    <p>[9] Sarayu Natarajan, Kushang Mishra, Suha Mohamed, and Alex S. Taylor. 25 Feb 2021. Just and equitable data labelling: Towards a responsible AI supply chain. Technical Report. Aapti Institute, Bangalore, India. <a href="https://uploads.strikinglycdn.com/files/7d492f74-a51f-423b-bf5d-65c9f88eee06/
                        AI_Data_Labelling_Report_DIGITAL_25FEB1033.pdf" targer="_new">URL</a>.</p>

                    <p>[10] Noopur Raval and Paul Dourish. 2016. Standing Out from the Crowd: Emotional Labor, Body Labor, and Temporal Labor in Ridesharing. In Proceedings of the 19th ACM Conference on Computer-Supported Cooperative Work amp; Social Computing
                        (San Francisco, California, USA) (CSCW ’16). Association for Computing Machinery, New York, NY, USA, 97–107. <a href="https://doi.org/10.1145/2818048.2820026" targer="_new">URL</a>.</p>

                    <p>[11] Morgan Klaus Scheuerman, Kandrea Wade, Caitlin Lustig, and Jed R. Brubaker. 2020. How We’ve Taught Algorithms to See Identity: Constructing Race and Gender in Image Databases for Facial Analysis. Proc. ACM Hum.-Comput. Interact.
                        4, CSCW1, Article 058 (May 2020), 35 pages. <a href="https://doi.org/10.1145/3392866" targer="_new">URL</a>.</p>

                    <p>[12] Anna Tsing. 2004. Friction: An Ethnography of Global Connection. Princeton University Press.</p>
                </div>

            </div>


            <!-- ... -->
</body>

</html>